{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\jsy11\\anaconda3\\envs\\study\\lib\\site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Using cached openai-1.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jsy11\\anaconda3\\envs\\study\\lib\\site-packages (from openai) (4.64.1)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jsy11\\anaconda3\\envs\\study\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\jsy11\\anaconda3\\envs\\study\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/58.3 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 30.7/58.3 kB 435.7 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 51.2/58.3 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 58.3/58.3 kB 340.6 kB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.14.6-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jsy11\\anaconda3\\envs\\study\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
      "   ---------------------------------------- 0.0/223.4 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 61.4/223.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 194.6/223.4 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 223.4/223.4 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB 855.2 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.9 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 276.5/381.9 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 381.9/381.9 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.14.6-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.4/1.9 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 12.1 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, h11, distro, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 pydantic-2.5.3 pydantic-core-2.14.6 sniffio-1.3.0 typing-extensions-4.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsy11\\AppData\\Local\\Temp\\ipykernel_16844\\3064988868.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key 입력. 만일 환경변수에 없으면, 프롬프트로 입력받음.\n",
    "client = OpenAI()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key is True:\n",
    "    openai_api_key = input(\"OpenAI API Key 입력: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 파일을 읽어오는 함수\n",
    "def get_md_files(directory):\n",
    "    md_files = glob.glob(os.path.join(directory, \"**/*.md\"), recursive=True)\n",
    "    return md_files\n",
    "\n",
    "# 읽어온 markdown 파일을 전처리하는 함수\n",
    "def process_file_content(file_path):\n",
    "    # Read and process the file content\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        # Replace new lines, URLs, and tags\n",
    "        content = content.replace('\\n', ' ').replace('\\r', ' ')\n",
    "        content = re.sub(r'http\\S+', '', content)  # Remove URLs\n",
    "        content = re.sub(r'\\{\\/\\*.*?\\*\\/\\}', '', content)  # Remove {/*text*/}\n",
    "        content = content.replace('---', '')\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../raw'\n",
    "md_files = get_md_files(directory)\n",
    "data = []\n",
    "for file_path in md_files:\n",
    "    title = os.path.basename(file_path).replace('.md', '')\n",
    "    content = process_file_content(file_path)\n",
    "    data.append({'title': title, 'content': content})\n",
    "df = pd.DataFrame(data, columns=['title', 'content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  여기서부터 시작!!!!!!!!!!!\n",
    "### 여기서부터 df=pd.read_csv(\"파일이름.csv\") 로 내가 만든 데이터를 불러오기. 파일 열의 형식은 `title`, `content`이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df =pd.read_csv('output2.csv')\n",
    "df =pd.read_csv('tokens_output2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens\n",
       "0        1                                                 []\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...\n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...\n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...\n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...\n",
       "...    ...                                                ...\n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...\n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...\n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...\n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...\n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...\n",
       "\n",
       "[1010 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Page','Tokens']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens\n",
       "0        1                                                 []\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...\n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...\n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...\n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...\n",
       "...    ...                                                ...\n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...\n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...\n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...\n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...\n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...\n",
       "\n",
       "[1010 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...\n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...\n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...\n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...\n",
       "5        6  ['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...\n",
       "...    ...                                                ...\n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...\n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...\n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...\n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...\n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...\n",
       "\n",
       "[1009 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df['Tokens'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "# df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 2000\n",
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # 일단 문장으로 쪼개기\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # 문장마다 몇 토큰 들어가는지 세어 주기.\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # 문장의 토큰 수와 현재까지의 토큰 수의 합이 최대 토큰 수를 초과하면, 해당 청크를 청크 목록에 추가하고 청크 및 현재까지의 토큰 수를 초기화한다.\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk) + \".\")\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened = []\n",
    "# 데이터 프레임 순회하기\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # If the content is None, go to the next row\n",
    "    if row[1]['Tokens'] is None:\n",
    "        continue\n",
    "\n",
    "    # If the number of tokens is greater than the max number of tokens, split the content into chunks\n",
    "    if row[1]['n_tokens'] > max_tokens:\n",
    "        shortened += split_into_many(row[1]['Tokens'])\n",
    "    \n",
    "    # Otherwise, add the content to the list of shortened texts\n",
    "    else:\n",
    "        shortened.append( row[1]['Tokens'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_large_text(large_text, max_tokens=2000):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokenized_text = enc.encode(large_text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in tokenized_text:\n",
    "        current_chunk.append(token)\n",
    "        current_length += 1\n",
    "\n",
    "        if current_length >= max_tokens:\n",
    "            chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# df['splitted_content'] = df['Text'].apply(split_large_text)\n",
    "# df = df.explode(\"splitted_content\")\n",
    "# df['spllitted_n_tokens'] = df['splitted_content'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "# df = df.reset_index( drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Page','splitted_content', 'spllitted_n_tokens']].rename(columns={'splitted_content':'content', 'spllitted_n_tokens':'n_tokens'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens  n_tokens\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...       618\n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...       130\n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...      1105\n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...       108\n",
       "5        6  ['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...        31\n",
       "...    ...                                                ...       ...\n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...       421\n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...       497\n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...       585\n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...       417\n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...        78\n",
       "\n",
       "[1009 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m###\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(combined)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined\n\u001b[1;32m----> 9\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombine_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jsy11\\anaconda3\\envs\\study\\Lib\\site-packages\\pandas\\core\\frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10346\u001b[0m )\n\u001b[1;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jsy11\\anaconda3\\envs\\study\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jsy11\\anaconda3\\envs\\study\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\jsy11\\anaconda3\\envs\\study\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m, in \u001b[0;36mcombine_info\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_info\u001b[39m(row):\n\u001b[0;32m      2\u001b[0m     title \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m     combined \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcontent\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m###\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(combined)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content' is not defined"
     ]
    }
   ],
   "source": [
    "def combine_info(row):\n",
    "    title = \" \".join(row['title'].split(\"-\"))\n",
    "\n",
    "    \n",
    "    combined = [f\"title: {title}\", f\"content: \\n{content}\"]\n",
    "    combined = \"\\n\\n###\\n\\n\".join(combined)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "df[\"combined\"] = df.apply(combine_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens  n_tokens\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...       618\n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...       130\n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...      1105\n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...       108\n",
       "5        6  ['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...        31\n",
       "...    ...                                                ...       ...\n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...       421\n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...       497\n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...       585\n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...       417\n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...        78\n",
       "\n",
       "[1009 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens  n_tokens\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...       618\n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...       130\n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...      1105\n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...       108\n",
       "5        6  ['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...        31\n",
       "...    ...                                                ...       ...\n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...       421\n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...       497\n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...       585\n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...       417\n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...        78\n",
       "\n",
       "[1009 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = df.Tokens.apply(get_embedding)\n",
    "# df.to_pickle(\"../../processed/test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "      <td>618</td>\n",
       "      <td>[0.0027860531117767096, 0.008122052997350693, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "      <td>130</td>\n",
       "      <td>[0.014323357492685318, -0.003350171959027648, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "      <td>1105</td>\n",
       "      <td>[-0.00623887125402689, -0.011925099417567253, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "      <td>108</td>\n",
       "      <td>[-0.012079219333827496, 0.002936786040663719, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...</td>\n",
       "      <td>31</td>\n",
       "      <td>[-0.00888099242001772, -0.012829650193452835, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "      <td>421</td>\n",
       "      <td>[-0.013197178021073341, -0.0050868378020823, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "      <td>497</td>\n",
       "      <td>[-0.01291818916797638, -0.014100742526352406, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "      <td>585</td>\n",
       "      <td>[-0.013505895622074604, -0.02323957160115242, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "      <td>417</td>\n",
       "      <td>[0.018290884792804718, -0.005117486231029034, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "      <td>78</td>\n",
       "      <td>[-0.015322505496442318, -0.008673368953168392,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens  n_tokens  \\\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...       618   \n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...       130   \n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...      1105   \n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...       108   \n",
       "5        6  ['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...        31   \n",
       "...    ...                                                ...       ...   \n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...       421   \n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...       497   \n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...       585   \n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...       417   \n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...        78   \n",
       "\n",
       "                                              embedding  \n",
       "1     [0.0027860531117767096, 0.008122052997350693, ...  \n",
       "2     [0.014323357492685318, -0.003350171959027648, ...  \n",
       "3     [-0.00623887125402689, -0.011925099417567253, ...  \n",
       "4     [-0.012079219333827496, 0.002936786040663719, ...  \n",
       "5     [-0.00888099242001772, -0.012829650193452835, ...  \n",
       "...                                                 ...  \n",
       "1005  [-0.013197178021073341, -0.0050868378020823, 0...  \n",
       "1006  [-0.01291818916797638, -0.014100742526352406, ...  \n",
       "1007  [-0.013505895622074604, -0.02323957160115242, ...  \n",
       "1008  [0.018290884792804718, -0.005117486231029034, ...  \n",
       "1009  [-0.015322505496442318, -0.008673368953168392,...  \n",
       "\n",
       "[1009 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../processed/test4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../processed/test4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['About', 'This', 'eBook', 'ePUB', 'is', 'an',...</td>\n",
       "      <td>618</td>\n",
       "      <td>[0.0027860531117767096, 0.008122052997350693, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Security', 'in', 'Computing', 'FIFTH', 'EDIT...</td>\n",
       "      <td>130</td>\n",
       "      <td>[0.014323357492685318, -0.003350171959027648, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Many', 'of', 'the', 'designations', 'used', ...</td>\n",
       "      <td>1105</td>\n",
       "      <td>[-0.00623887125402689, -0.011925099417567253, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Executive', 'Editor', 'Bernard', 'Goodwin', ...</td>\n",
       "      <td>108</td>\n",
       "      <td>[-0.012079219333827496, 0.002936786040663719, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...</td>\n",
       "      <td>31</td>\n",
       "      <td>[-0.00888099242001772, -0.012829650193452835, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...</td>\n",
       "      <td>421</td>\n",
       "      <td>[-0.013197178021073341, -0.0050868378020823, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>['PrivacyPreserving', 'Data', 'Mining', 'Priva...</td>\n",
       "      <td>497</td>\n",
       "      <td>[-0.01291818916797638, -0.014100742526352406, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>['Human', 'Vandals', 'Interception', 'of', 'Se...</td>\n",
       "      <td>585</td>\n",
       "      <td>[-0.013505895622074604, -0.02323957160115242, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>['Situation', 'IX', 'True', 'Representation', ...</td>\n",
       "      <td>417</td>\n",
       "      <td>[0.018290884792804718, -0.005117486231029034, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>['What', 'Are', 'the', 'Critical', 'Issues', '...</td>\n",
       "      <td>78</td>\n",
       "      <td>[-0.015322505496442318, -0.008673368953168392,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page                                             Tokens  n_tokens  \\\n",
       "1        2  ['About', 'This', 'eBook', 'ePUB', 'is', 'an',...       618   \n",
       "2        3  ['Security', 'in', 'Computing', 'FIFTH', 'EDIT...       130   \n",
       "3        4  ['Many', 'of', 'the', 'designations', 'used', ...      1105   \n",
       "4        5  ['Executive', 'Editor', 'Bernard', 'Goodwin', ...       108   \n",
       "5        6  ['To', 'Willis', 'Ware', 'a', 'hero', 'of', 'c...        31   \n",
       "...    ...                                                ...       ...   \n",
       "1005  1006  ['Big', 'Data', 'Conclusion', 'Exercises', 'Cl...       421   \n",
       "1006  1007  ['PrivacyPreserving', 'Data', 'Mining', 'Priva...       497   \n",
       "1007  1008  ['Human', 'Vandals', 'Interception', 'of', 'Se...       585   \n",
       "1008  1009  ['Situation', 'IX', 'True', 'Representation', ...       417   \n",
       "1009  1010  ['What', 'Are', 'the', 'Critical', 'Issues', '...        78   \n",
       "\n",
       "                                              embedding  \n",
       "1     [0.0027860531117767096, 0.008122052997350693, ...  \n",
       "2     [0.014323357492685318, -0.003350171959027648, ...  \n",
       "3     [-0.00623887125402689, -0.011925099417567253, ...  \n",
       "4     [-0.012079219333827496, 0.002936786040663719, ...  \n",
       "5     [-0.00888099242001772, -0.012829650193452835, ...  \n",
       "...                                                 ...  \n",
       "1005  [-0.013197178021073341, -0.0050868378020823, 0...  \n",
       "1006  [-0.01291818916797638, -0.014100742526352406, ...  \n",
       "1007  [-0.013505895622074604, -0.02323957160115242, ...  \n",
       "1008  [0.018290884792804718, -0.005117486231029034, ...  \n",
       "1009  [-0.015322505496442318, -0.008673368953168392,...  \n",
       "\n",
       "[1009 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  여기서부터는 테스트 코드!!!!!!!!!!!!!!!!!!!\n",
    "### 실제 개발환경에서 배포할 때 확인할 목적!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../processed/test4.pkl\")\n",
    "def create_context(\n",
    "    question, df, max_len=3000\n",
    "):\n",
    "    q_embeddings = client.embeddings.create(input=question, model='text-embedding-ada-002').data[0].embedding\n",
    "    df[\"distances\"] = df[\"embedding\"].apply(lambda x: cosine(q_embeddings, x))\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        returns.append(row[\"Tokens\"])\n",
    "    return \"\\n\\n===\\n\\n\".join(returns)\n",
    "\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    question=\"What is difference between useEffect and useLayoutEffect in React?\",\n",
    "    max_len=3000,\n",
    "    debug=False,\n",
    "):\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "    )\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"},\n",
    "                {\"role\": \"user\", \"content\": f\"context: {context}\\n\\n---\\n\\n Question: {question}, 한국어로 대답해줘.\"}\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'컴퓨터 보안은 컴퓨터 시스템의 취약점을 식별하고 이를 이용하여 발생할 수 있는 피해를 방지하고 막기 위한 조치들을 총칭하는 개념입니다. 이는 악의적인 공격, 데이터 유출, 시스템 마비 등으로부터 컴퓨터 시스템을 보호하는 것을 목표로 합니다.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"컴퓨터 보안이 뭐야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
